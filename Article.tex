\documentclass[times, twoside]{zHenriquesLab-StyleBioRxiv}
\usepackage{blindtext}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}

\DeclareMathOperator*{\E}{\mathbb{E}}
\newcommand{\norm}[1]{\left\lVert #1 \right\rVert}

% Please give the surname of the lead author for the running footer
\leadauthor{Denovellis} 

\begin{document}

\title{A state space model for characterizing the trajectory dynamics of replay}
\shorttitle{Replay Dynamics}

% Use letters for affiliations, numbers to show equal authorship (if applicable) and to indicate the corresponding author
\author[1]{Eric L. Denovellis}
\author[2, 3]{Anna K. Gillespie}
\author[2, 3]{Michael E. Coulter}
\author[4]{Uri T. Eden}
\author[1, 2, 3, \Letter]{Loren M. Frank}


\affil[1]{Howard Hughes Medical Institute, University of California, San Francisco, San Francisco, California}
\affil[2]{Department of Physiology, University of California, San Francisco, San Francisco, California}
\affil[3]{Kavli Institute for Fundamental Neuroscience, University of California, San Francisco, San Francisco, California}
\affil[4]{Department of Mathematics and Statistics, Boston University, Boston, Massachusetts}

\maketitle

%TC:break Abstract
%the command above serves to have a word count for the abstract
\begin{abstract}
During sleep and immobility, hippocampal place cells fire in sequences consistent with temporally compressed versions of trajectories previously run by the animal. These replayed sequences are hypothesized to be an important mechanism for the retrieval of spatial memory in service of consolidation and decision-making. Replay events are typically evaluated based on whether they activate sequences of place cells that represent spatially continuous trajectories through the environment, but recent work has shown that these events can have more complex dynamics. For example, sequences can alternate between hovering on a particular spatial location and continuous movement or can represent continuous trajectories in other spatial environments, which may appear spatially incoherent in the context of the current environment.

To quantify the structure of replay events, we develop a state space model that uses a combination of discrete and continuous latent state to decompose place cell sequences into categories based on their latent dynamics. Each discrete latent “category” is associated with a type of continuous latent dynamic—spatially stationary, spatially fragmented or spatially continuous. This allows for (1) direct comparison between different categories of sequence dynamics, (2) expression of our confidence in one or more categories explaining the data, and (3) characterization of the transitions between categories. In addition, the model can function in 2D, avoiding linearization errors on more complicated environments. We demonstrate the utility of this model on simulated and real data of an animal performing a spatial memory task.

\end {abstract}
%TC:break main
%the command above serves to have a word count for the abstract

\begin{keywords}
Hippocampus | Replay | State Space
\end{keywords}

\begin{corrauthor}
%\texttt{loren{@}phy.ucsf.edu}
loren\at phy.ucsf.edu
\end{corrauthor}

\section*{Introduction}
Neurons in the hippocampus preferentially fire in response to specific locations in an environment, firing in sequence as the animal moves through space. When the animal is asleep or immobile, cells also fire in sequence, forming trajectory-like representations that can recapitulate sequences previously observed when the animal was running (cite). These sequences are thought to be important for memory consolidation or prospective decision making. Therefore, characterizing the trajectory of hippocampal sequences is important for understanding memory consolidation and prospective decision making.

An often used method for characterizing the trajectories of hippocampal sequences is the Bayesian decoder (cite). The Bayesian decoder consists of two steps: first, the probability of position is computed at each time bin using the previously estimated place fields from the population of neurons. Second---assuming the trajectory of the replay is of constant velocity---a line is fit that maximizes the probability of position over time. If the probabilities near the best fit line are high relative to shuffled distribution, the replay is analyzed. Trajectories that travel less than a certain distance are often excluded (cite).

Although the Bayesian decoder has been useful in characterizing replay---particularly in the case of linear tracks---the assumption of constant velocity is a strong assumption about the dynamics of replay. Because replays are typically judged based on how well their trajectories conform to the constant velocity assumption, only a subset of sharp wave ripples or multiunit high synchrony events are typically analyzed (37\% of events\cite{KarlssonAwakereplayremote2009}, 16\%  of events\cite{DavidsonHippocampalReplayExtended2009} 5-20\% Tingley and Peyrache 2020). This potentially excludes replays with more complicated, non-constant velocity dynamics.

Recognizing this, several studies have moved away from the constant velocity assumption, using the weighted mean or maximum of each posterior time bin and connecting each time bin with a line (cite). For example, using this approach, Pfeiffer and Foster \cite{PfeifferAutoassociativedynamicsgeneration2015} found that replays can alternate between representing a single location and sequential spatial trajectories. On the other hand, Stella et al. found that replays are more spatially continuous, following Brownian diffusion dynamics. One possibility for the difference between the studies is that this method is dependent on the size of the time bin, does not take into account the uncertainty of the posterior, and can lead to highly variable trajectories.

State space models are a well-understood, well-known statistical solution to these problems. By mathematically modeling the relationship between the data and latent dynamics, state space models make the assumptions of the model explicit and interpretable. State space models have successfully been applied to decoding movement from the spiking of cells in the hippocampus (Brown et al 1998) and in classifying replay trajectories in real-time settings (Deng et al. 2016). However, these state space models have generally assumed one dynamic persists through the replay, which would not capture more complicated, non-constant velocity trajectories.

Here, we define a state space model of replay that characterizes trajectories as a mixture of three speed dynamics: stationary trajectories, continuous trajectories many times the typical speed of the animal, and fragmented trajectories. These dynamics represent the categories neuroscientists studying replay typically focus on when investigating replay. We show how this model can take advantage of clusterless decoding---which relates multiunit spike wave form features to position without spike sorting--giving us more information about the population spiking activity.  Using this, we find that this model can identify replays with spatially coherent trajectories as well as replays with more complicated representations that can have a mixture of stationary, continuous, and fragmented dynamics. We also show that, by using this model, we are able to interpret a larger fraction of the replays than previous studies. Surprisingly, we find that many replay trajectories, although spatially coherent, are slower in speed than reported in previous studies including stationary events, which represent a single location, and slowly moving trajectories that are more consistent with the animal's movement speed. This challenges the notion that replay trajectories only consist of trajectories that are many times faster than the animal's behavior.


\section*{Results}
\begin{figure*}%[tbhp]
\centering
\includegraphics[width=0.80\linewidth]{figures/Figure1/Figure1_v3}
\caption{Components of the state space model and demonstration on simulated data. \textbf{(A)} 19 simulated place cells that exhibit three different sequence patterns. For the first third of time, one cell fires repeatedly, representing one stationary location. For the second third of time, the cells fire in sequence, representing a smooth continuous trajectory through space. For the last third cells fire in an incoherent pattern, representing a non-smooth fragmented trajectory through space. \textbf{(B)} Like the Bayesian Decoder, the state space model uses estimates of cells' place fields from when the animal is moving and combines them with the observed spikes in (A) to compute the likelihood of position for each time step. \textbf{(C)} This is combined with an explicit model of each dynamic state--which determines how latent position can change based on the posterior from the previous time step. In the hover state, this is modeled as the identity matrix because the position remains the same. In the continuous state, the dynamics are modeled as a Gaussian random walk, meaning the next possible position is likely to be spatially close. In the fragmented state, the dynamics are modeled as uniform, meaning the next position is equally likely to be anywhere. Note that the states displayed only reflect the within-state dynamics. \textbf{(D)} The probability of remaining in a particular state versus switching to another state. This is modeled as having a high probability of remaining in a particular state with a small probability of switching to one of the other states at each time step. \textbf{(F)} The state space model uses the components in A-D over all time to decode the joint probability of latent position and dynamic state. The joint probability can be summarized by marginalizing over latent position (left panel) to get the probability of each dynamic state over time (lines). This can also be used to get an estimate of latent position over time (right panel). \textbf{(G)} The probability of each state given a particular constant speed trajectory. Each speed corresponds to a simulated spiking sequence at that speed. The lines correspond to the average probability of that state over the sequence. Dotted line represents the 0.8 classification threshold we use to classify each range of speeds and shaded regions correspond to the classification we have given the range of speeds.
}
\label{1}
\end{figure*}
\subsection*{Overview of the model}
In order to introduce and validate the model, we demonstrate how the model works on a simulated dataset (Figure \ref{1}). We simulated 19 Poisson spiking cells with Gaussian place fields on a 180 cm virtual linear track. Each place field has a 36 cm variance and a 15 Hz peak firing rate, which is spaced every 10 cm along the virtual track. We then apply our decoding algorithm to the spiking sequence in Figure \ref{1}A. For the first third of this sequence, a single place cell fires repeatedly. For the middle third of the sequence, the cells fire in sequential spatial order. For the last third, the cells fire in a incoherent spatial order. These firing patterns represent three different types of sequence dynamics, which we call stationary, continuous, and fragmented, respectively. The goal of our model is to characterize replay events in terms of these three dynamical states at every time point.

Decoding the spiking sequence dynamics requires specifying two elements: the data model and the dynamics model. For the data model, our decoder is the same as the Bayesian decoder. We compute an estimate of how each cell's firing rate varies over position (the place field, Figure \ref{1}B). This is used during decoding to compute the Poisson likelihood of position over time given the spiking sequence of interest. In contrast to the Bayesian decoder, we use small time bins (2 ms vs. 20 ms) because we are able to take advantage of the prior placed on the dynamics by the state space model. This allows us to detect changes on smaller time scales than would be possible with the Bayesian decoder.

Next, we specify a dynamics model for how latent position--the "mental" position of the animal represented by the cells--can evolve in each of these sequences (Figure \ref{1}C). We do this by defining a state transition matrix, which defines how the latent position can change from the previous time step.. In the stationary state, we expect latent position to not change between time steps, so we use an identity state transition matrix. In the continuous state, we expect the latent position to be "spatially close" to the position in the previous time step, so we use a Gaussian random walk state transition matrix. This means that, for a given latent position, the probability of moving to another position is modeled by a Gaussian centered at that position and "spatially close" is defined by the variance of the Gaussian. In our case, since we are interested in identifying replays that move at speeds much faster than the animal's speed, we set this to 6.0 cm. This means that with a 2 ms time step, the latent position is 95\% likely to be within 4.90 cm of the previous latent position (or 24.5 m/s) which is consistent with replay speeds observed in previous studies \cite{DavidsonHippocampalReplayExtended2009, PfeifferAutoassociativedynamicsgeneration2015}. In the fragmented state, we expect that the latent position can move to any available position. We model this using a uniform state transition matrix, which makes all positions equally likely.

Finally, we specify how likely we are to stay in a dynamic state versus changing to another state (Figure \ref{1}D). In order to be conservative, we assume that each dynamic is likely to dominate for the entirety of the replay, with a small probability of switching to one of the other states. Therefore, we set the probability of staying in a state to 0.98 for each 2 ms time step. Because the probability of changing dynamics follows a geometric distribution, this corresponds to an expected duration of 100 ms for staying in a particular state.

Once we have specified the data and dynamics model, we have fully specified the state space model. We use acausal decoding, meaning that we use all information from the past and future spikes, to estimate the joint posterior probability of position and dynamic state. We summarize the resulting posterior with two quantities: the probability of each state over time and the probability of position over time (Figure \ref{1}F, left and right plot respectively). From these two summaries, we can see that the model successfully captures the dynamics of the population spiking activity in Figure \ref{1}A. The probability of the stationary state has high probability at the beginning of the simulated replay, reflecting the consistent spiking from one cell. This gives way to the continuous state, reflecting the trajectory-like spiking from the population of cells. Then the fragmented state dominates for the last third when the population spiking is not spatially coherent. We can also see that these three states are reflected in the estimate of latent position of the animal.  Importantly, we get a much less variable estimate due to the correct specification of the dynamics.

One way to interpret the probabilities in our model is as a classifier of speeds of replay. To demonstrate this, we applied the model to simulated replays of increasing speed(Figure \ref{1}G), from 1 cm/s to 10,000 m/s. From this, we can see that not only are there regions of speed that correspond to our three states being high probable (where highly probable means over 0.8), there are in-between speeds where two of the states dominate with high probability; that is, the sum of two of the states' probabilities is over 0.8. In this manuscript, we will refer to these as mixture states. For example, when the stationary state has a probability of 0.5 and the continuous has a probability of 0.5, we call this a stationary-continuous mixture (light blue, Figure \ref{1}G). By using this classification scheme, we can characterize the speed or set of speeds in a replay.

In order to verify that the model was robust to the choice of probability of staying in a state, we decoded the spiking sequence in Figure \ref{1}A with different probabilities of staying in the same state versus switching to another state (Figure 1-Supplemental Figure 1). We found that for a large range of plausible probabilities of staying in one of the states (0.9 - 0.9999), the model still correctly identified the dynamic states with high probability.

\begin{figure*}%[tbhp]
\centering
\includegraphics[width=0.80\linewidth]{figures/Figure2/Figure2_v3}
\caption{Demonstration of the state space model on real data using both sorted and clusterless spikes on the same SWR. \textbf{(A)} Decoding using sorted spikes (arranged top to bottom). In the top panel, 31 cells on a W-track ordered according to linearized position by their place field peaks. The second panel shows the probability of each dynamic over time as in Figure 1F. Shaded regions correspond to the speed classifications as in Figure 1G. The third panel shows the estimated probability of latent position over the course of the SWR as it travels down the center arm toward the right arm. L, R, C correspond to the position of the left, right and center wells respectively. The animal's position is indicated by the red triangle. \textbf{(B)} Decoding using clusterless spikes. The top panel shows multiunit spiking activity from each tetrode. Other panels have the same convention as(A).  \textbf{(C)} 1D MAP estimate of the latent position in (A) projected back into 2D. Color indicates time. The animal's position is denoted by the red circle. Light grey lines show the animal's 2D position over the entire epoch. L, R, and C correspond to the left, right and center well as in (A). \textbf{(D)} 1D MAP estimate of the latent position in (B) projected back into 2D. Figure conventions are the same as in (C).
}
\label{2}
\end{figure*}
\subsection*{The model finds known continuous replays with sorted and clusterless spikes}
Next, we wanted to validate our model on real hippocampal data. We first applied the decoding algorithm to a sharp wave ripple (SWR) with clear sequential population activity (Figure \ref{2}A, top panel) from 31 cells recorded in hippocampus while the rat was performing a spatial alternation task on the W-track. We see that the probability of being in the continuous state is high throughout the SWR, with the probability of being in a stationary state being slightly higher at the beginning and end of the SWR (Figure \ref{2}A, middle panel). Using our speed classification, this means that the speed of the replay starts slower---as a mixture of continuous and stationary states---and then speeds up and slows down again. We can see this in the posterior probability of linear position over time as the replay travels down the center arm and up the right arm (Figure \ref{2}A, bottom panel) as well as the projection of the maximum of this trajectory to 2D (Figure \ref{2}C). Moreover, when we apply the same model using 2D position, we get a similar result (Figure 2-Supplemental 1A).

One problem with using spikes from cells identified using spike sorting is that there is potentially a lot of information lost by determining the identity of each cell---many spikes are discarded with information about position because it could not be assigned to one cell. Therefore, we wanted to use a method which directly relates multiunit spike waveform features to position without spike sorting, which we call clusterless decoding. Clusterless decoding has been successfully used to identify theta sequences and replay sequences in the hippocampus (\cite{KloostermanBayesiandecodingusing2014, ChenTransductiveneuraldecoding2012,DengRapidclassificationhippocampal2016}, Kay et al. 2020). Here, if we apply it to the same SWR as the sorted spikes, we get similar decoding and classification of the sequence (Figure \ref{2}B, D), both in using 1D linearized and 2D position (Figure 2-Supplemental 1B). Note that, using clusterless decoding, the estimate of the posterior probability of position is much more certain than the corresponding posterior probability of position using sorted spikes (Figure \ref{2}D vs C).

\subsection*{The model finds replays that would not normally be identified by the Bayesian Decoder}
After validating our model on a single SWR, we then applied our decoding algorithm to hippocampal recordings from 10 animals performing the W-track spatial alternation task (tetrodes = [10, 24], brain areas = [CA1, CA2, CA3]; some data previously used in \cite{KarlssonAwakereplayremote2009}). We observed many replays that were classified as continuous throughout the entirety of SWR and would have been identified by the Bayesian Decoder (Figure 2-Supplemental 2A-C) . However, we also observed replays that did not have this structure, but could be interpreted in terms of our model. For example, we observed trajectories that started in one direction and reversed back to the original position (Figure \ref{3}A), trajectories that stayed in one position (Figure \ref{3}A), trajectories that started in a single location trajectories, jumped to a


\subsection*{Most replays are spatially coherent, but slower than reported}

\begin{figure*}%[tbhp]
\centering
\includegraphics[width=0.80\linewidth]{figures/Figure3/Figure3_v3}
\caption{A-D. Four examples of replays that would not be well-characterized by using the Bayesian decoder. Figure conventions are the same as in Figure 2. \textbf{(A)} A replay that starts down the center arm away from the animal's position at the center well, slows down, and returns back. \textbf{(B)} A replay that stays at the left well for the entirety of the SWR while the animal is in the center arm. \textbf{(C)} A replay that begins stationary at the left well and then jumps to the middle of the right arm and proceeds up the right arm to the right well. \textbf{(D)} A replay that begins stationary at the left well, jumps to the center arm, proceeds away from the center well, jumps to the right arm, proceeds back toward the center well, and then becomes fragmented. \textbf{(E)} Percentage of SWRs in each epoch that has some content that falls into one of the categories (Hover, Hover-Continuous-Mix, Continuous, Fragmented-Continuous-Mix, or Fragmented). \textbf{(F)} Of the classified content, the percentage of SWRs in each epoch that have some Hover, Hover-Continuous-Mix, or Continuous content. \textbf{(G)} Of the classified content, the percentage of SWR in each epoch that has some Continuous content.
}
\label{Figure3}
\end{figure*}

\subsection*{Most replays only have one dynamic but some do not}

\begin{figure*}%[tbhp]
\centering
\includegraphics[width=0.80\linewidth]{figures/Figure4/Figure4_v3}
\caption{
Analysis of SWRs from all animals. \textbf{(A)} UpSet plot of the most common combinations of dynamics within each ripple. Each row represents a possible category present in the SWR. Each column represents a set of dynamics categories, where filled-in black dots with an edge between the dots indicates that multiple categories are present in the SWR (at temporally distinct times). The sets are ordered by how often they occurred as indicated by the bar plot above each category. The total number of each category is indicated by the rotated bar plot on the left. \textbf{(B)} Distribution of the duration of each dynamic category within a SWR. \textbf{(C)} The distance of the average latent position from the animal's position for each dynamic category within each SWR. \textbf{(D)} Position of hovers on the W-track at least 30 cm away from the animal's position. \textbf{(E)} Distribution of multiunit spike rates for each dynamic category within each SWR.
}
\label{Figure4}
\end{figure*}

\subsection*{Many replays have time periods where the latent position remains at just one position and that position can be both local and non-local to the animal's position}
\subsection*{Non-local hovers occur all over the track, but mostly at reward wells and choice points.}

\subsection*{Removing spatial information from the model leads to fewer classified ripples}
\begin{figure}%[tbhp]
\centering
\includegraphics[width=0.80\linewidth]{figures/Figure5/Figure5_v1}
\caption{Comparison of real vs. position shuffled data for two epochs from different animals. Line represents the percent of SWR classified in that epoch for real data. The histogram represents the distribution after 50 shuffles of the position data. Position data was shuffled by resampling with replacement from the set of all observed positions in that epoch, destroying position information but preserving spiking timing.}
\label{Figure5}
\end{figure}
\section*{Discussion}


\begin{acknowledgements}
\end{acknowledgements}

\section*{References}
\bibliography{refs}

\onecolumn
\newpage

\section*{Methods}
\subsection*{Recording Locations and Techniques}
Ten male Long Evans rats (500-700 g, 4-9 months old) were trained on a W-track spatial alternation task. XX rats contributed to a previous study \cite{KarlssonAwakereplayremote2009}. Neural activity was recorded in CA1, CA2, CA3, MEC, Subiculum, and DG depending on the rat. We only used hippocampal tetrodes (CA1, CA2, CA3) in this study.

\subsection*{Behavioral Task}
The behavioral task is a W-track spatial alternation task as presented in \cite{KarlssonAwakereplayremote2009}. For each day, animals alternated between 15 minute sessions in a rest box and 15 minutes in the W-track. The behavioral task is a W-track spatial alternation task as presented in \cite{KarlssonAwakereplayremote2009}. For each day, animals alternated between 15 minute sessions in a rest box and 15 minutes in the W-track. Only run epochs with at least 9 hippocampal principal cells that fired at least 100 spikes were included in the analysis.

Only run epochs with at least 9 hippocampal principal cells that fired at least 100 spikes were included in the analysis.

\subsection*{Linearization}
To decrease the time it takes to run the model, the 2D position of the animal is converted into a 1D position. This is done by first defining a graph representation of the track, where edges correspond to segments of the W-track and nodes represent intersection points between those segments. Then, based on the algorithm in \cite{NewsonHiddenMarkovmap2009}, we use a Hidden Markov Model (HMM) to classify which track segment the animal is on. This algorithm was developed to track cars on roads with GPS signals. Using the HMM prevents sudden jumps from one track segment to another, which is particularly important near intersections when we are tracking the head position. Briefly, the observation model of the HMM is Gaussian and it models the likelihood of being on a track segment as the Gaussian distance to that segment with a 5 cm standard deviation. The state transition model is an empirically estimated state transition that changes with each time point that tries to ensure that the euclidean distance between successive position estimates is similar to the shortest path distance along the graph between successive position estimates. A slight bias of 0.1 is given to the diagonal to encourage staying on the same track segment. The most likely track segment the animal is on is computed using the Viterbi algorithm. After finding the track segment that corresponds to each 2D position, the 2D position is projected onto the track segment. This allows us to define a distance from the center well in terms of shortest path length on the track, where 0 cm represents the center well position. The linear distance can then be converted into a linear position by assigning each track segment a position in 1D space. The code used for linearization can be found at \url{https://github.com/Eden-Kramer-Lab/loren_frank_data_processing}.

\subsection*{SWR Detection}
Sharp wave ripples were detected using the same method as in \cite{Kayhippocampalnetworkspatial2016}. Briefly, each LFP was filtered between 150-250 Hz, squared and then summed across tetrodes--forming a single population trace over time. This trace was smoothed with a Gaussian with a 4 ms standard deviation and the square root of this trace was taken to get an estimate of the population ripple band power. Candidate SWR times were found by z-scoring the population power trace and finding times when the z-score exceeded 2 standard deviations for a minimum of 15 ms and the speed of the animal was less than 4 cm/s. The SWR times were then defined as times when the z-score was greater than the mean and contained the candidate SWR times. The code used for ripple detection can be found at \url{https://github.com/Eden-Kramer-Lab/ripple_detection}.

\subsection*{Spike Sorting}

\subsection*{Simulated Data}

\subsection*{The Model}

\subsection*{Encoding - Clusterless}
In order to encode how each tetrode's unsorted spiking activity relates to position, we use a marked point process framework. For each multiunit spike during movement (defined as time periods when the running speed is greater than 4 cm/s), the associated waveform features (the marks) and position are recorded in a (n-spikes, n-features + n-position-dimensions) array. In our case, the waveform features correspond to the max amplitude observed on each tetrode wire at the time of the multiunit spike. This array is used as the training samples in a kernel density estimator during the decoding step.

\subsection*{Encoding - Sorted Spikes}
In order to encode how each cell's spiking activity relates to position (the place field), we fit a generalized linear model (GLM) with a Poisson response distribution to each cell's spiking activity during movement (defined as time periods when the running speed is greater than 4 cm/s). We estimate the parameters $\beta$, which consist of $\beta_{0}$, the average firing rate over time, and $\beta_{i}$, weights for third degree B-splines basis functions $f_{i}$ over position (or tensor products of the B-splines when position is two dimensional). B-spline basis functions are used because place field firing activity is assumed to vary smoothly over position and this prior knowledge can be exploited to reduce the total number of model parameters needed. Each basis function is spaced every 5 cm over the range of the position and zero constrained so that the change encoded by the parameters is relative to the baseline firing rate. We use a log link function to convert the linear combination of parameters to an instantaneous firing rate over time $\lambda(t)$ to ensure the rate is always positive. 

$$log(\lambda(t)) = \beta_{0} + \sum_{i} f_{i}(position)\beta_{i}$$

A small L2 penalization term $-\lambda\norm{\beta_{i}}_{2}^{2}$ used to prevent model fitting instability when spiking activity is very low. We set this to 0.5 for all cells. Fitting is done by maximizing the penalized likelihood using a Newton-Raphson algorithm.

\subsection*{Decoding - Clusterless}

\subsection*{Classification of Dynamic States}
We used a threshold of 0.8 to classify the probability of each state into 5 categories. Time periods during sharp wave ripples are labeled as Hover, Continuous, or Fragmented when the probability of each state is above 0.8. Time periods are labeled as Hover-Continuous-Mix or Fragmented-Continuous-Mix when the sum of Hover and Continuous or Fragmented and Continuous are above 0.8, respectively. Time periods where none of these criterion are met are considered unclassified because there is not strong enough evidence for one or more of the states.

\subsection*{Replay distance from animal}
Replay distance from the animal is defined as the shortest path distance along the track graph between the animal's projected position on the track graph (see Linearization) and the MAP estimate of the joint posterior marginalized over state, which is defined as the center of the position bin with the greatest posterior value.

\subsection*{Software and Code availability}
Python code used for analysis and generating figures in the paper is available at: \url{https://github.com/Eden-Kramer-Lab/replay_trajectory_paper}. Code for the classifier is available in a separate software repository to facilitate code reuse at: \url{https://github.com/Eden-Kramer-Lab/replay_trajectory_classification}. All code is open-source and licensed under the MIT Software License. Classifier code can be easily installed as a python package with all requisite dependencies using pip or conda. See software repositories for specific details.

\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Supplementary Information %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\beginsupplement
\captionsetup*{format=largeformat}

\begin{figure*}%[tbhp]
\centering
\includegraphics[width=0.80\linewidth]{figures/Figure1-supplemental1/Figure1_v1_supplemental1}
\caption{The model is robust to changes in the discrete transition matrix. Each plot shows the probability of each dynamic on simulated data example from Figure 1 with a different diagonal value--which governs the probability of remaining in that state. The off-diagonal values--the probability of switching to one of the other states--are set to be equally likely with the remainder of the probability, as in Figure 1D. The first plot (upper left) shows the case when all states are equally likely. The diagonal increases from left to right, top to bottom, until the case where the diagonal is one and the off-diagonal is zero--i.e. the case where there is no probability of switching to another state.}
\label{fig:Figure1-Figure supplement 1}
\end{figure*}

\begin{figure*}%[tbhp]
\centering
\includegraphics[width=0.80\linewidth]{figures/Figure2-supplemental1/Figure2_v2-supplemental1}
\caption{Decoding the same SWR in Figure 2 using 2D clusterless and sorted spikes. \textbf{(A)} The left plot shows the spikes from cells arranged by the linear position of the peak of place field as in Figure 2. The middle plot shows the probability of each dynamic over time from the 2D decode. Shaded regions indicate classification category as in Figure 1G and 2. The rightmost plot shows the MAP estimate of the latent position with color indicating time. The latent position posterior summed over time is shown in purple underneath. The light grey lines represent the position of the animal over the entire epoch and the red dot represents the animal's position. \textbf{(B)} Same as in A, but with clusterless decoding.}
\label{fig:Figure2-Figure supplement 1}
\end{figure*}

\begin{figure*}%[tbhp]
\centering
\includegraphics[width=0.80\linewidth]{figures/Figure2-supplemental2/Figure2_v2-supplemental2}
\caption{A-C. Examples of continuous replays. Left panel uses the same conventions as Figure 2A and 2B. Right panel shows the 1D MAP estimate projected back to 2D as in Figure 2C. Color indicates time. Light grey lines indicate the animal's position over the entire epoch.}
\label{fig:Figure2-Figure supplement 2}
\end{figure*}

\begin{figure*}%[tbhp]
\centering
\includegraphics[width=0.80\linewidth]{figures/Figure3-supplemental1/Figure3_v2_supplemental1}
\caption{More examples of replays that would not be well-characterized by using the Bayesian decoder. Conventions are the same as in Figure 3. \textbf{(A)} A continuous replay that starts in the left arm back toward the center well, jumps to the right arm and continuous back toward the center well. \textbf{(B)} A continuous replay that travels down the right arm toward the center well, proceeds past the choice point toward the left well and then returns back to the choice point. \textbf{(C)} A replay that starts down the left arm toward the center arm and turns into a hover near the choice point. \textbf{(D)} The first half is a fragmented replay and the second half is unclassified. \textbf{(E)} A hover in the first half of the SWR on the right arm and then a hover in the SWR at the left well. \textbf{(F)} A hover that starts at the animal's position at the center well, then jumps to the left well and comes back toward the center well.
}
\label{fig:Figure3-Figure supplement 1}
\end{figure*}


%TC:endignore
%the command above ignores this section for word count

\end{document}
